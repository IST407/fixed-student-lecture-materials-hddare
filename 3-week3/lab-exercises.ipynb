{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 1:**\n",
    "\n",
    "Last week, we started looking at the Titanic data.  Load that data again. For features that you think are of minimal importance and / or have too many NAs to make imputation feasible, drop those features.  For those that seem important, use a `SimpleImputer` to impute the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass      0\n",
       "name        0\n",
       "sex         0\n",
       "age         0\n",
       "sibsp       0\n",
       "parch       0\n",
       "ticket      0\n",
       "fare        0\n",
       "embarked    0\n",
       "survived    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "titanic_data = pd.read_csv(\"data/titanic.csv\")\n",
    "td_clean = titanic_data.drop('cabin', axis=1)\n",
    "td_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "td_clean['age'] = td_imputer.fit_transform(td_clean[['age']])\n",
    "td_clean['fare'] = td_imputer.fit_transform(td_clean[['fare']])\n",
    "td_imputer = SimpleImputer(strategy='most_frequent')\n",
    "td_clean['embarked'] = td_imputer.fit_transform(td_clean[['embarked']])[:, 0]\n",
    "td_clean.isna().sum()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 2**\n",
    "\n",
    "Sklearn does not handle strings.  Use an encoder to transform any string columns into numbers. If there are any categorical columns where label encoding won't work, use a one-hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   remainder__pclass  remainder__name  remainder__sex  remainder__age  \\\n",
      "0                1.0             21.0             0.0         29.0000   \n",
      "1                1.0             23.0             1.0          0.9167   \n",
      "2                1.0             24.0             0.0          2.0000   \n",
      "3                1.0             25.0             1.0         30.0000   \n",
      "4                1.0             26.0             0.0         25.0000   \n",
      "\n",
      "   remainder__sibsp  remainder__parch  remainder__ticket  remainder__fare  \\\n",
      "0               0.0               0.0              187.0         211.3375   \n",
      "1               1.0               2.0               49.0         151.5500   \n",
      "2               1.0               2.0               49.0         151.5500   \n",
      "3               1.0               2.0               49.0         151.5500   \n",
      "4               1.0               2.0               49.0         151.5500   \n",
      "\n",
      "   remainder__embarked  remainder__survived  \n",
      "0                  2.0                  1.0  \n",
      "1                  2.0                  1.0  \n",
      "2                  2.0                  0.0  \n",
      "3                  2.0                  0.0  \n",
      "4                  2.0                  0.0  \n",
      "   pclass                                             name     sex      age  \\\n",
      "0       1                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
      "1       1                   Allison, Master. Hudson Trevor    male   0.9167   \n",
      "2       1                     Allison, Miss. Helen Loraine  female   2.0000   \n",
      "3       1             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
      "4       1  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
      "\n",
      "   sibsp  parch  ticket      fare    cabin embarked  survived  \n",
      "0      0      0   24160  211.3375       B5        S         1  \n",
      "1      1      2  113781  151.5500  C22 C26        S         1  \n",
      "2      1      2  113781  151.5500  C22 C26        S         0  \n",
      "3      1      2  113781  151.5500  C22 C26        S         0  \n",
      "4      1      2  113781  151.5500  C22 C26        S         0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "string_columns = td_clean['embarked', '']\n",
    "onehot_encoder = OneHotEncoder(drop='first', sparse_output=False)  # drop='first' to avoid multicollinearity\n",
    "\n",
    "# Use ColumnTransformer to apply OneHotEncoder to all string columns\n",
    "column_transformer = ColumnTransformer(transformers=[('onehot', onehot_encoder, string_columns)], remainder='passthrough')\n",
    "\n",
    "# Apply transformation and return as DataFrame\n",
    "td_clean_encoded = pd.DataFrame(column_transformer.fit_transform(td_clean), columns=column_transformer.get_feature_names_out())\n",
    "\n",
    "# Check the transformed dataset\n",
    "print(td_clean_encoded.head())\n",
    "print(titanic_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 3**\n",
    "\n",
    "Using 5-fold cross-validation, examine the performance of a LogisticRegression classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "X = td_clean.drop('survived', axis=1)\n",
    "y = td_clean['survived']\n",
    "result = cross_val_score(lr, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 4**\n",
    "\n",
    "Replace the logistic regression classifier with a decision tree classifier.  Which works better?  Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4351145 , 0.65267176, 0.08778626, 0.16030534, 0.57471264])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "X = td_clean.drop('survived', axis=1)\n",
    "y = td_clean['survived']\n",
    "result = cross_val_score(dt, X, y, cv=5)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 5:** \n",
    "\n",
    "See if you can get the decision tree classifier to perform better by adjusting your imputation procedure to use a KNNImputer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 6:**\n",
    "\n",
    "Try using a `GridSearchCV` to optimize the DecisionTree algorithm.  What is the best performance you can achieve?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
